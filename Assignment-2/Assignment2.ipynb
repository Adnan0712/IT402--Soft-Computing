{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance function\n",
    "def euclidean_distance(x1, x2):\n",
    "    sum = 0\n",
    "    for i in range(len(x1)):\n",
    "      sum += (x1[i]-x2[i])**2\n",
    "    return math.sqrt(sum)\n",
    "\n",
    "# KNN classifier\n",
    "def knn_predict(X_train, y_train, x_test, k):\n",
    "    distances = [euclidean_distance(x, x_test) for x in X_train]\n",
    "    nearest_indices = np.argsort(distances)[:k]\n",
    "    nearest_labels = [y_train[i] for i in nearest_indices]\n",
    "    most_common_string = max(set(nearest_labels), key=nearest_labels.count)\n",
    "    return most_common_string\n",
    "\n",
    "# Evaluate KNN classifier\n",
    "def evaluate_classifier(X_train, y_train, X_test, y_test, k):\n",
    "    predictions = [knn_predict(X_train, y_train, x_test, k) for x_test in X_test]\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(y_test, predictions, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    # print(list(y_test))\n",
    "    confusion_mat = confusion_matrix(list(y_test), predictions)\n",
    "    # print(list(y_test),(predictions))\n",
    "    return precision, recall, f1, accuracy, confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split data\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "data = data.values.tolist()\n",
    "data = np.array(data)\n",
    "X = data[:,:4]\n",
    "X = X.astype(float)\n",
    "y = data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica'], dtype='<U32')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Cross Validation and without in-build KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for k=3:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "\n",
      "Results for k=5:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform classification for k=3 and k=5\n",
    "k_values = [3, 5]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "for k in k_values:\n",
    "    precision, recall, f1, accuracy, confusion_mat = evaluate_classifier(X_train, y_train, X_test, y_test, k)\n",
    "    print(f\"Results for k={k}:\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_mat)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Cross Validation and without in-build KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for k=3:\n",
      "Precision: 0.9700000000000001\n",
      "Recall: 0.9666666666666667\n",
      "F1 Score: 0.966750208855472\n",
      "Accuracy: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      "[[10.  0.  0.]\n",
      " [ 0.  9.  0.]\n",
      " [ 0.  1. 10.]]\n",
      "\n",
      "\n",
      "Results for k=5:\n",
      "Precision: 0.9700000000000001\n",
      "Recall: 0.9666666666666667\n",
      "F1 Score: 0.966750208855472\n",
      "Accuracy: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      "[[10.  0.  0.]\n",
      " [ 0.  9.  0.]\n",
      " [ 0.  1. 10.]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_values = [3, 5]\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "# count = 0\n",
    "\n",
    "for k in k_values:\n",
    "  count = 0\n",
    "  confusion_matx = []\n",
    "  for train_index, test_index in k_fold.split(X_train):\n",
    "    x_train = X[train_index]\n",
    "    Y_train = y[train_index]\n",
    "    precision, recall, f1, accuracy, confusion_mat = evaluate_classifier(x_train, Y_train, X_test, y_test, k)\n",
    "    # print(confusion_mat)\n",
    "    if(count==0):\n",
    "      count+=1\n",
    "      confusion_matx = confusion_mat\n",
    "    else:\n",
    "      confusion_matx+=confusion_mat\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    accuracies.append(accuracy)\n",
    "  print(f\"Results for k={k}:\")\n",
    "  print(\"Precision:\", statistics.mean(precisions))\n",
    "  print(\"Recall:\", statistics.mean(recalls))\n",
    "  print(\"F1 Score:\", statistics.mean(f1s))\n",
    "  print(\"Accuracy:\", statistics.mean(accuracies))\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(confusion_matx/10)\n",
    "  print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
